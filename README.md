# Speech-Tranformer-Pytorch
An Pytorch Implement of Tranformer On ASR.
Environments: Pytorch 0.4.1„ÄÅ Python 3.6
## IO for Kaldi
Use [kaldi_io](https://github.com/vesis84/kaldi-io-for-python) to read feature from ark file.
If you want to load features from ark file generated by Kaldi. Please set config file:
```yaml
feature_type: kaldi_ark
```
## Extract Features Online
This library([python_speech_features](https://github.com/jameslyons/python_speech_features)) provides common speech features for ASR including MFCCs and filterbank energies.
```yaml
# online_mfcc or online_fbank
feature_type: online_fbank
```
means that you want to extract fbank features online by python_speech_features. 'online_mfcc' is also avalible.

## Train
```python
python train.py -config config/character.yaml
```
## Test
```python
python eval.py -config config/character.yaml
```
## Predict
if you want to recognize a wav file, please type:
```python
python predict.py -load_model model.chkpt -wav example.wav
```
Or, if you want to recognize a list of wav file, please type:
```python
python predict.py -load_model model.chkpt -wavscp wav.scp --output decoded.txt
```
## Done
- [x] Self-Attention
- [x] Multi-Head Attention
- [x] BeamSearch
- [x] Multi-GPU
## TO DO
- [ ] Label Smoothing
- [ ] Teacher Forcing
- [ ] Input Feeding
- [ ] Local Attention
- [ ] Intergrate with Language Model
- [ ] Model Compression
## Results
We list some Results on [aisell](http://www.openslr.org/33/). There are 4300+ characters in this corpus. However, we just chose the first 3000 frequency characters as modeling units.

## Acknowledgements
Thanks for [attention-is-all-you-need-pytorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch).
## Reference
[1] Vaswani A, Shazeer N, Parmar N, et al. [Attention is all you need](https://arxiv.org/abs/1706.03762)[C]//Advances in Neural Information Processing Systems. 2017: 5998-6008.
